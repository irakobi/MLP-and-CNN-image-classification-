{"cells":[{"cell_type":"markdown","metadata":{"id":"CXbQHQNzgCFf"},"source":["# Import the Necessary Libraries"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"BYjUtoJbgCFj","executionInfo":{"status":"ok","timestamp":1709053164172,"user_tz":-120,"elapsed":5276,"user":{"displayName":"Obed Irakoze","userId":"02748002398163718276"}}},"outputs":[],"source":["import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","import numpy as np\n","from torchsummary import summary # pip install torch-summary\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"27zWsYzYgCFk","executionInfo":{"status":"ok","timestamp":1709053164172,"user_tz":-120,"elapsed":14,"user":{"displayName":"Obed Irakoze","userId":"02748002398163718276"}},"outputId":"83312659-2130-4dca-a6ec-f1d5c905ea15"},"outputs":[{"output_type":"stream","name":"stdout","text":["Device:  cuda\n"]}],"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","print(\"Device: \", device)"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"OG7IgQzXgCFl","executionInfo":{"status":"ok","timestamp":1709053164173,"user_tz":-120,"elapsed":9,"user":{"displayName":"Obed Irakoze","userId":"02748002398163718276"}}},"outputs":[],"source":["seed = 42\n","torch.manual_seed(seed)\n","torch.cuda.manual_seed(seed)\n","torch.backends.cudnn.deterministic = True"]},{"cell_type":"markdown","metadata":{"id":"lA76UV3HgCFm"},"source":["# Download the CIFAR 10 Dataset"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KLAxnULsgCFm","executionInfo":{"status":"ok","timestamp":1709053169456,"user_tz":-120,"elapsed":5291,"user":{"displayName":"Obed Irakoze","userId":"02748002398163718276"}},"outputId":"ebf7698f-8977-41b8-c4f7-4fb7c482e155"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 170498071/170498071 [00:01<00:00, 89881892.66it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/cifar-10-python.tar.gz to ./data\n","Files already downloaded and verified\n"]}],"source":["# Get the training data and create a transform to ensure the data is made up of tensors\n","# why are we not normalizing the data between 0 and 1?\n","transform = transforms.Compose([transforms.ToTensor()])\n","train_data = torchvision.datasets.CIFAR10(root='./data', train=True, download = True, transform=transform)\n","\n","# load the training data and transform it\n","train_dataloader = torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=True, num_workers=2)\n","\n","# Get the test data\n","test_data = torchvision.datasets.CIFAR10(root='./data', train=False, download = True, transform=transform)\n","\n","# Now load the test data with a batch size of 32: Do we need to shuffle the test data?\n","test_dataloader = torch.utils.data.DataLoader(test_data, batch_size=32, shuffle=False, num_workers=2)"]},{"cell_type":"markdown","metadata":{"id":"6rxkMZ65gCFn"},"source":["# Building the CNN Model"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xrzPiUdvgCFn","executionInfo":{"status":"ok","timestamp":1709053582453,"user_tz":-120,"elapsed":400,"user":{"displayName":"Obed Irakoze","userId":"02748002398163718276"}},"outputId":"b63be80a-c051-4a09-9b4a-527483004a43"},"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1           [-1, 32, 31, 31]           1,568\n","       BatchNorm2d-2           [-1, 32, 31, 31]              64\n","            Conv2d-3           [-1, 32, 31, 31]           9,248\n","       BatchNorm2d-4           [-1, 32, 31, 31]              64\n","            Conv2d-5           [-1, 64, 31, 31]          18,496\n","       BatchNorm2d-6           [-1, 64, 31, 31]             128\n","            Conv2d-7           [-1, 64, 31, 31]          36,928\n","       BatchNorm2d-8           [-1, 64, 31, 31]             128\n","            Linear-9                  [-1, 128]       7,872,640\n","      BatchNorm1d-10                  [-1, 128]             256\n","           Linear-11                   [-1, 10]           1,290\n","================================================================\n","Total params: 7,940,810\n","Trainable params: 7,940,810\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.01\n","Forward/backward pass size (MB): 2.82\n","Params size (MB): 30.29\n","Estimated Total Size (MB): 33.12\n","----------------------------------------------------------------\n"]}],"source":["import math\n","\n","# Calculate the output size of a convolutional layer with \"same\" padding\n","def calculate_output_size(input_size, kernel_size, stride, padding):\n","    return math.floor((input_size + 2 * padding - kernel_size) / stride) + 1\n","\n"," # write your code below and ensure your padding is correct and well calculated\n","# calculating the padding\n","def calculate_padding(input_size, kernel_size, stride):\n","    padding = ((input_size - 1) * stride - input_size + kernel_size) // 2\n","    return math.floor(padding)\n","\n","class CNN(torch.nn.Module):\n","\n","    def __init__(self):\n","        super(CNN, self).__init__()\n","        # Create instance variables for the layers you will pass in the forward method\n","\n","\n","        # padding_number = 1\n","        padding_number1 = calculate_padding(32, 4, 1)\n","        self.convLayer1 = torch.nn.Conv2d(in_channels=3, out_channels=32, kernel_size=4, stride=1, padding=padding_number1)\n","        self.bn1 = torch.nn.BatchNorm2d(32)\n","\n","        padding_number2 = calculate_padding(32, 3, 2)\n","        self.convLayer2 = torch.nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=2, padding=padding_number2)\n","        self.bn2 = torch.nn.BatchNorm2d(32)\n","\n","        padding_number3 = calculate_padding(32, 3, 1)\n","        self.convLayer3 = torch.nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=padding_number3)\n","        self.bn3 = torch.nn.BatchNorm2d(64)\n","\n","        padding_number4 = calculate_padding(32, 3, 2)\n","        self.convLayer4 = torch.nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=2, padding=padding_number4)\n","        self.bn4 = torch.nn.BatchNorm2d(64)\n","\n","        # Calculate the output size of the last convolutional layer\n","        last_conv_output_size = calculate_output_size(32, 4, 1, padding_number1)  # Assuming input size 32x32\n","        last_conv_output_size = calculate_output_size(last_conv_output_size, 3, 2, padding_number2)\n","        last_conv_output_size = calculate_output_size(last_conv_output_size, 3, 1, padding_number3)\n","        last_conv_output_size = calculate_output_size(last_conv_output_size, 3, 2, padding_number4)\n","\n","\n","        self.fclayer1 = torch.nn.Linear(64 * last_conv_output_size * last_conv_output_size, 128)\n","        self.bn5 = torch.nn.BatchNorm1d(128)\n","\n","        self.fclayer2 = torch.nn.Linear(128 , 10)\n","\n","\n","    def forward(self, x):\n","        # complete your forward method\n","        x=torch.nn.functional.leaky_relu(self.bn1(self.convLayer1(x)))\n","        x=torch.nn.functional.leaky_relu(self.bn2(self.convLayer2(x)))\n","\n","        x=torch.nn.functional.leaky_relu(self.bn3(self.convLayer3(x)))\n","        x=torch.nn.functional.leaky_relu(self.bn4(self.convLayer4(x)))\n","\n","        x = x.view(x.size(0), -1)\n","\n","        x=torch.nn.functional.leaky_relu(self.bn5(self.fclayer1(x)))\n","\n","        x=torch.nn.functional.dropout(x,p=.5)\n","\n","        x=self.fclayer2(x)\n","\n","        return torch.nn.functional.log_softmax(x, dim=-1)\n","\n","cnn_model = CNN().to(device)\n","summary(cnn_model, (3, 32, 32))"]},{"cell_type":"markdown","metadata":{"id":"yJpQEwIggCFo"},"source":["# Set the Loss Function and Optimizer"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"ol6pjT9kgCFo","executionInfo":{"status":"ok","timestamp":1709053195655,"user_tz":-120,"elapsed":2,"user":{"displayName":"Obed Irakoze","userId":"02748002398163718276"}}},"outputs":[],"source":["criterion = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(cnn_model.parameters(), lr=0.0005)"]},{"cell_type":"markdown","metadata":{"id":"_pHTxlqtgCFp"},"source":["# Write the Train Function"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"o3hS4tszgCFp","executionInfo":{"status":"ok","timestamp":1709053196334,"user_tz":-120,"elapsed":5,"user":{"displayName":"Obed Irakoze","userId":"02748002398163718276"}}},"outputs":[],"source":["def train(dataloader, model, criterion, optimizer):\n","    model.train()\n","    batch_bar = tqdm(total=len(dataloader), position=0, leave=False, dynamic_ncols=True, desc='Train')\n","    total_loss = 0\n","    total_accuracy = 0\n","\n","    for i, (imgs, labels) in enumerate(dataloader):\n","        # write your code below for the train function\n","        # Move data to device which is cpu\n","        imgs, labels = imgs.to(device), labels.to(device)\n","\n","        # Forward pass\n","        outputs = model(imgs)\n","\n","        # Compute loss\n","        loss = criterion(outputs, labels)\n","\n","        # Backpropagation\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        # Compute accuracy\n","        _, predicted = torch.max(outputs, 1)\n","        accuracy = (predicted == labels).sum().item()\n","\n","        total_loss += loss.item() * imgs.size(0)\n","        total_accuracy += accuracy\n","        # total_samples += labels.size(0)\n","\n","        # update the progress bar\n","        batch_bar.set_postfix(loss=loss.item(), accuracy=100 * accuracy / len(labels))\n","        batch_bar.update()\n","    batch_bar.close()\n","    return total_loss/len(dataloader), 100*total_accuracy/(len(dataloader)*32)"]},{"cell_type":"markdown","metadata":{"id":"RlPX8rQDgCFp"},"source":["# Write the Evaluate Function to get the Test Accuracy"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"EPvqo55SgCFq","executionInfo":{"status":"ok","timestamp":1709053196334,"user_tz":-120,"elapsed":5,"user":{"displayName":"Obed Irakoze","userId":"02748002398163718276"}}},"outputs":[],"source":["def evaluate(dataloader, model):\n","    model.eval()\n","    # write your code for the evaluate function\n","    accuracy = 0\n","    total = 0\n","\n","    with torch.no_grad():\n","        for data in dataloader:\n","            images, labels = data\n","            images, labels = images.to(device), labels.to(device)\n","\n","            # Forward pass\n","            outputs = model(images)\n","\n","            # Get predicted labels\n","            _, predicted = torch.max(outputs.data, 1)\n","\n","            # Total number of samples\n","            total += labels.size(0)\n","\n","            # Number of correctly classified samples\n","            accuracy += (predicted == labels).sum().item()\n","\n","    # Calculate test accuracy\n","    test_accuracy = 100 * accuracy / total\n","    return test_accuracy\n"]},{"cell_type":"markdown","metadata":{"id":"HuFuzJJqgCFq"},"source":["# Train the CNN Model"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vIriaST2gCFq","executionInfo":{"status":"ok","timestamp":1709053444357,"user_tz":-120,"elapsed":248027,"user":{"displayName":"Obed Irakoze","userId":"02748002398163718276"}},"outputId":"639c579b-48f5-4c54-9b9c-ef25d6078b1f"},"outputs":[{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 1/10 - Train Loss: 43.8190 - Train Accuracy: 51.1896\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 2/10 - Train Loss: 32.8833 - Train Accuracy: 63.8176\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 3/10 - Train Loss: 28.4931 - Train Accuracy: 68.8680\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 4/10 - Train Loss: 25.5283 - Train Accuracy: 71.9630\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 5/10 - Train Loss: 23.0007 - Train Accuracy: 74.9420\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 6/10 - Train Loss: 20.8042 - Train Accuracy: 77.4172\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 7/10 - Train Loss: 18.7343 - Train Accuracy: 79.4706\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 8/10 - Train Loss: 17.0749 - Train Accuracy: 81.3980\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 9/10 - Train Loss: 15.5405 - Train Accuracy: 82.8835\n"]},{"output_type":"stream","name":"stderr","text":["                                                                                     "]},{"output_type":"stream","name":"stdout","text":["Epoch 10/10 - Train Loss: 14.1802 - Train Accuracy: 84.2710\n"]},{"output_type":"stream","name":"stderr","text":["\r"]}],"source":["for epoch in range(0, 10):\n","    train_loss, train_acc = train(train_dataloader, cnn_model, criterion, optimizer)\n","    print(f\"Epoch {epoch+1}/{10} - Train Loss: {train_loss:.4f} - Train Accuracy: {train_acc:.4f}\")"]},{"cell_type":"markdown","metadata":{"id":"E2ntdV0hgCFq"},"source":["# Get the Test Accuracy"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"khUg60zogCFq","executionInfo":{"status":"ok","timestamp":1709053446971,"user_tz":-120,"elapsed":2633,"user":{"displayName":"Obed Irakoze","userId":"02748002398163718276"}},"outputId":"9f07759f-e3c3-46f1-8f4d-fdec74dee133"},"outputs":[{"output_type":"stream","name":"stdout","text":["The test accuracy is:  72.04\n"]}],"source":["test_acc = evaluate(test_dataloader, cnn_model)\n","print(\"The test accuracy is: \",test_acc)\n"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"XSwArs0HgCFr","executionInfo":{"status":"ok","timestamp":1709053446971,"user_tz":-120,"elapsed":3,"user":{"displayName":"Obed Irakoze","userId":"02748002398163718276"}}},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}